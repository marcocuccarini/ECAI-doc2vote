{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a45641-296d-41cd-8e3d-d5eb8e4be56f",
   "metadata": {},
   "source": [
    "# Notebook for reproduce experiments of the paper doc2vote paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706b8961-bb4c-4aee-bce2-bf40ef133fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.dataset import Dataset\n",
    "from classes.evaluator import Evaluator\n",
    "from classes.model import BM25\n",
    "\n",
    "import ir_datasets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4f67e7-0849-4030-a529-324280427af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(path):\n",
    "\n",
    "\t with open(path) as f:\n",
    "\n",
    "\t \td = json.load(f)\n",
    "\t \treturn d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9d9ce-2ff5-4bed-b52f-6a3be6e9b44d",
   "metadata": {},
   "source": [
    "### Create the dataset instance and initialize the attributes of the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43bb43e9-6b15-4ff1-b127-7cc01f66a3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28196bc7940d4a6ba1d089e17616fa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_n=10\n",
    "\n",
    "\n",
    "dataset_config = extract_json(\"/Users/marco/Documents/GitHub/ECAI-doc2vote/code/configuration/configDatasetMarco.json\")\n",
    "\n",
    "dataset=Dataset(dataset_config['dataset_name_test_2'])\n",
    "\n",
    "#extarct all the passage of the dataset reduce\n",
    "dataset.list_raduce_passage()\n",
    "\n",
    "#add all the augmented file, it is applied a filter becouse it in not able\n",
    "#to create a dictionary with the complete dataset\n",
    "dataset.add_augmented_file()\n",
    "\n",
    "#create the feature \n",
    "\n",
    "dataset.raduce_passage()\n",
    "\n",
    "#\n",
    "\n",
    "dataset.join_passage_base_aug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e748f5e-0bbf-4ac9-9a3f-980fe44e5be6",
   "metadata": {},
   "source": [
    "### Test for classical test with model BM25 on the reduce dataset MSMarco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a50aaea0-5b9f-4a4d-bc9e-2f24ae309cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = BM25(list(dataset.reduce_passages.values()))\\n\\n\\nscore, dict_prediction = model.ranking_score(dataset.query, dataset.reduce_passages, top_n)\\n\\nevaluator= Evaluator(dict_prediction,dataset.query_passage)\\n\\nrank=evaluator.extract_ranking(top_n)\\n\\n\\nprint(\"BM25\", evaluator.mean_reciprocal_rank(list(rank.values())))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = BM25(list(dataset.reduce_passages.values()))\n",
    "\n",
    "\n",
    "score, dict_prediction = model.ranking_score(dataset.query, dataset.reduce_passages, top_n)\n",
    "\n",
    "evaluator= Evaluator(dict_prediction,dataset.query_passage)\n",
    "\n",
    "rank=evaluator.extract_ranking(top_n)\n",
    "\n",
    "\n",
    "print(\"BM25\", evaluator.mean_reciprocal_rank(list(rank.values())))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740ead93-1310-4155-9935-ed352df2c63c",
   "metadata": {},
   "source": [
    "### Test for doc2vote test with model BM25 on the reduce dataset MSMarco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "667a604b-9ee3-475f-bf59-9f148192a581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = BM25(list(dataset.reduce_passages_base_aug.values()))\\n\\n\\nscore, dict_prediction = model.ranking_score(dataset.query, dataset.reduce_passages_base_aug, top_n)\\n\\nevaluator= Evaluator(dict_prediction,dataset.query_passage)\\n\\nrank=evaluator.extract_ranking(top_n)\\n\\n\\nprint(\"BM25 with doc2vec:\", evaluator.mean_reciprocal_rank(list(rank.values())))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = BM25(list(dataset.reduce_passages_base_aug.values()))\n",
    "\n",
    "\n",
    "score, dict_prediction = model.ranking_score(dataset.query, dataset.reduce_passages_base_aug, top_n)\n",
    "\n",
    "evaluator= Evaluator(dict_prediction,dataset.query_passage)\n",
    "\n",
    "rank=evaluator.extract_ranking(top_n)\n",
    "\n",
    "\n",
    "print(\"BM25 with doc2vec:\", evaluator.mean_reciprocal_rank(list(rank.values())))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118a547-2eb9-47c5-8908-df120a9f99a4",
   "metadata": {},
   "source": [
    "### Test for doc2vote test with model BM25 on the reduce dataset MSMarco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa5cf4e-8121-45a0-be83-a8fe8db709b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n=10\n",
    "aug_num=50\n",
    "dataset.passage_creation_vote(aug_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324d82a4-1929-4897-a3b5-4c9a02ad3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_passages=[x[1] for x in dataset.list_doc2vote]\n",
    "index_passages=[x[0] for x in dataset.list_doc2vote]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d182a02e-38a6-4352-a3b2-2f1b0d45ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = BM25(list(list_passages))\n",
    "score, dict_prediction = model.ranking_score_partial(dataset.query, list_passages, index_passages, top_n*aug_num)\n",
    "\n",
    "from collections import Counter\n",
    "counts_per_id = {\n",
    "    key: dict(sorted(Counter(value).items(), key=lambda item: item[1], reverse=True))\n",
    "    for key, value in dict_prediction.items()\n",
    "}\n",
    "\n",
    "dict_new={}\n",
    "for j in counts_per_id.keys():\n",
    "    \n",
    "    dict_new[j]=counts_per_id[j].keys()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "evaluator= Evaluator(dict_new,dataset.query_passage)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e55b35c-3925-467d-9ac3-50d649c86df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=evaluator.extract_ranking(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc0b6b9-aef5-4baa-9c95-1e43122e11ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 with doc2vote: 0.7186751723191808\n"
     ]
    }
   ],
   "source": [
    "print(\"BM25 with doc2vote:\", evaluator.mean_reciprocal_rank(list(rank.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f383fb-ee76-43c0-a903-e8564e4fd69b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
